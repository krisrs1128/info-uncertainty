---
title: "Teaching attention, part 3 / N: Thinking more creatively"
date: 2019-07-19 09:12 -4
---

To this point, our memory mechanisms all have had the same flavor. We had a
running summary $$h_t$$, which we update with every new input, though gating
might mean we prevent some coordinates from changing too much. However, it's
possible to think more creatively about how we should record and attend to new
memories. For example,

1. We don't need to throw away all but the last $$h_t$$ when making some
   prediction. We've been saying that a model "forgets" if there are values for
   $$h_t$$ early on which are erased by new inputs. But what if we just kept all
   the $$h_t$$'s, and avoided overload by having a smart lookup strategy?
2. Why are we forcing the memory $$h_t$$ to architecturally mirror the inputs
   $$x_t$$ -- that is, why does $$h_t$$ need to be a sequence? Considering that,
   due to gating, we only update some cells at a time, it makes sense to design
   architectures specifically adapted to recording and looking up useful
   summaries.
3. We've assumed a pretty diligent sequential processor, which knows to check
   every input datapoint as it arrives. What if we had a lazy one, which played
   it fast and loose and tried to process only those inputs that seemed really
   crucial to the process.
   
These sorts of preposterous questions will help illuminate the more fundamental
principles of memory and attention in deep learning[^1].

First though, a warning, reiterating points from part 1. Attention is not a
well-defined, clearly demarcated mathematical term. It is a principle that is
useful for reasoning about many problems, but which is always in flux, as people
find variants that are suited to their particular settings.

To keep our discussion grounded, and to leave you with something mathematical
examples (and not just cool paper titles) that you can take home, we're going to
explore a few attention mechanisms in detail, before briefly touring across
other highlights of the memory and attention literature.

Our three methods mirror the three questions from before.

## Attention in Translation Models



[^1] I mean, if there are any.
